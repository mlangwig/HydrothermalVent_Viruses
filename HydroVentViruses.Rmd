---
title: "Hydrothermal Vent Viruses Protocol"
author: "Maggie Langwig"
date: "8/21/2022"
output:
  html_document: rmdformats::downcute
  toc: yes
  toc_float: yes
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Organizing the 43 assemblies

## Renaming
1. 11 assemblies do not have the sample name associated with the file so I am adding it.
```{bash, eval = FALSE}
cd /storage1/data12/Projects/Vent_Viruses/Assemblies_Renamed

for i in *.fasta; do awk '/>/{sub(">","&"FILENAME"_");sub(/\.fasta/,x)}1' $i >> $i.renamed; done
```

2. Special naming for S009:
```{bash, eval = FALSE}
for i in *.fasta; do awk '/>/{sub(">","&"FILENAME"_");sub(/\_metaspades_scaffolds.min1000.fasta/,x)}1' $i >> $i.renamed; done
```

3. Adding site identifier to assembly names (after checking your sed first!)

### Brothers UC
```{bash, eval = FALSE}
sed -i 's/>/>Brothers_UC_/g' S010_metaspades_scaffolds.min1000.fasta
```

```{bash, eval = FALSE}
sed -i 's/>/>Brothers_UC_/g' S011_metaspades_scaffolds.min1000.fasta
```

```{bash, eval = FALSE}
sed -i 's/>/>Brothers_UC_/g' S147_metaspades_scaffolds.min1000.fasta
```
### Brothers LC
```{bash, eval = FALSE}
sed -i 's/>/>Brothers_LC_/g' S014_metaspades_scaffolds.min1000.fasta
```

```{bash, eval = FALSE}
sed -i 's/>/>Brothers_LC_/g' S016_metaspades_scaffolds.min1000.fasta
```
### Brothers NWCA
```{bash, eval = FALSE}
sed -i 's/>/>Brothers_NWCA_/g' S013_metaspades_scaffolds.min1000.fasta
```

```{bash, eval = FALSE}
sed -i 's/>/>Brothers_NWCA_/g' S017_metaspades_scaffolds.min1000.fasta
```

```{bash, eval = FALSE}
sed -i 's/>/>Brothers_NWCA_/g' S142_metaspades_scaffolds.min1000.fasta
```

```{bash, eval = FALSE}
sed -i 's/>/>Brothers_NWCA_/g' S143_metaspades_scaffolds.min1000.fasta
```

```{bash, eval = FALSE}
sed -i 's/>/>Brothers_NWCA_/g' S144_metaspades_scaffolds.min1000.fasta
```

```{bash, eval = FALSE}
sed -i 's/>/>Brothers_NWCA_/g' S145_metaspades_scaffolds.min1000.fasta
```
### Brothers NWCB
```{bash, eval = FALSE}
sed -i 's/>/>Brothers_NWCB_/g' S012_metaspades_scaffolds.min1000.fasta
```

```{bash, eval = FALSE}
sed -i 's/>/>Brothers_NWCB_/g' S139_metaspades_scaffolds.min1000.fasta
```

```{bash, eval = FALSE}
sed -i 's/>/>Brothers_NWCB_/g' S140_metaspades_scaffolds.min1000.fasta
```

```{bash, eval = FALSE}
sed -i 's/>/>Brothers_NWCB_/g' S141_metaspades_scaffolds.min1000.fasta
```

```{bash, eval = FALSE}
sed -i 's/>/>Brothers_NWCB_/g' S146_metaspades_scaffolds.min1000.fasta
```
### Brothers Diffuse
```{bash, eval = FALSE}
sed -i 's/>/>Brothers_Diffuse_/g' S009_metaspades_scaffolds.min1000.fasta

sed -i 's/>/>Brothers_Diffuse_/g' S015_metaspades_scaffolds.min1000.fasta
```
### ELSC Abe
```{bash, eval = FALSE}
sed -i 's/>/>ELSC_Abe_/g' A1_metaspades_scaffolds.min1000.fasta

sed -i 's/>/>ELSC_Abe_/g' A3_metaspades_scaffolds.min1000.fasta

sed -i 's/>/>ELSC_Abe_/g' 128-326.fasta
```
### ELSC Tui Malila
```{bash, eval = FALSE}
sed -i 's/>/>ELSC_Tui_Malila_/g' T10_metaspades_scaffolds.min1000.fasta

sed -i 's/>/>ELSC_Tui_Malila_/g' T11_metaspades_scaffolds.min1000.fasta

sed -i 's/>/>ELSC_Tui_Malila_/g' T2_metaspades_scaffolds.min1000.fasta

sed -i 's/>/>ELSC_Tui_Malila_/g' 132-544.fasta

sed -i 's/>/>ELSC_Tui_Malila_/g' 134-614.fasta
```
### ELSC Bowl
```{bash, eval = FALSE}
sed -i 's/>/>ELSC_Bowl_/g' M1_metaspades_scaffolds.min1000.fasta

sed -i 's/>/>ELSC_Bowl_/g' M2_metaspades_scaffolds.min1000.fasta
```
### ELSC Mariner
```{bash, eval = FALSE}
sed -i 's/>/>ELSC_Mariner_/g' 131-447.fasta

sed -i 's/>/>ELSC_Mariner_/g' M10_metaspades_scaffolds.min1000.fasta

sed -i 's/>/>ELSC_Mariner_/g' M17_metaspades_scaffolds.min1000.fasta
```
### ELSC Vai Lili
```{bash, eval = FALSE}
sed -i 's/>/>ELSC_Vai_Lili_/g' V2_metaspades_scaffolds.min1000.fasta
```
### Guaymas
```{bash, eval = FALSE}
sed -i 's/>/>Guaymas_/g' 4559-240.fasta

sed -i 's/>/>Guaymas_/g' 4561-380.fasta

sed -i 's/>/>Guaymas_/g' 4561-384.fasta

sed -i 's/>/>Guaymas_/g' 4571-419.fasta
```
### EPR
```{bash, eval = FALSE}
sed -i 's/>/>EPR_/g' 4281-140.fasta

sed -i 's/>/>EPR_/g' PIR-30.fasta
```
### MAR Rainbow
```{bash, eval = FALSE}
sed -i 's/>/>MAR_Rainbow_/g' 354-166.fasta

sed -i 's/>/>MAR_Rainbow_/g' 355-202.fasta
```
### MAR Lucky
```{bash, eval = FALSE}
sed -i 's/>/>MAR_Lucky_/g' 356-284.fasta

sed -i 's/>/>MAR_Lucky_/g' 356-308.fasta
```

After scaffold renaming, I used `mv` commands to rename files.

# Identifying viruses using VIBRANT
VIBRANT filters to remove scaffolds <1kb so not filtering assembly before. ID's dsDNA, ssDNA, and RNA viruses
```{bash, eval = FALSE}
for i in Assemblies_Renamed/*.fasta; do VIBRANT_run.py -i $i -t 15; done
```

## Count the number of viruses identified by VIBRANT
```{bash, eval = FALSE}
grep ">" -c VIBRANT_*/VIBRANT_phages*/*combined.fna | cut -f2 -d : | paste -sd+ | bc
```
Total of 53,135 viruses identified

# Run CheckV
CheckV provides quality estimates of viral genomes. I'm running this first to determine how many medium and high confidence viruses we have. If it's a lot I'll only focus on these.
```{bash, eval = FALSE}
find -type f -name "*combined.fna" | xargs cp -t ../Virus_Genomes/fna/

nohup checkv end_to_end Virus_Genomes/fna/All_Viruses.fna CheckV_Output -t 20 &
```

Check how many medium and high quality viruses:
```{bash,  eval = FALSE}
grep -v 'Low-quality\|Not-determined' quality_summary.tsv | wc
```
Result: 1,165 medium and high quality viruses (exclude header)
146 complete viruses
1,031 proviruses, or integrated viruses

## Grab only the medium and high quality viruses
Grab only the medium and high quality viruses predicted by CheckV
```{bash,  eval = FALSE}
grep -v 'Low-quality\|Not-determined' quality_summary.tsv > MedHighQual_Viruses.tsv

cut -f1 MedHighQual_Viruses.tsv > MedHighQual_Viruses_list.txt 

perl /storage1/data12/scripts/screen_list_new.pl CheckV_Output/MedHighQual_Viruses_list.txt Virus_Genomes/fna/All_Viruses.fna keep > MedHighQual_Viruses.fna
```

Cp the faa viruses into a new folder

```{bash,  eval = FALSE}
find -type f -name "*combined.faa" | xargs cp -t ../Virus_Genomes/faa
```

Get a list of the faa scaffold names for medium and high quality viruses:
```{bash,  eval = FALSE}
for i in `cat ../../CheckV_Output/MedHighQual_Viruses_list.txt`; do grep $i *.faa >> MedHighQual_faa_list.txt; done

sed 's/>/\t/g' MedHighQual_faa_list.txt | cut -f2 > MedHighQual_faa_list_final.txt
```

Extract the faa seqs by name:
```{bash,  eval = FALSE}
perl /storage1/data12/scripts/screen_list_new.pl MedHighQual_faa_list_final.txt All_Viruses.faa keep > MedHighQual_Viruses.faa
```

# Organizing the MAGs
I want to associate the site names and file name of each MAG to the scaffold header. I am not being as careful about renaming for the MAGs as I was for the assemblies, meaning I am just using general site name and not specific (e.g. Brothers vs Brothers_UC).

## Brothers Volcano
```{bash,  eval = FALSE}
pwd

/storage1/data12/Projects/Vent_Viruses/MAGs_Renamed/Brothers_Volcano

rename 's/scaf2bin.//g' *.fasta

rename 's/^/Brothers_/g' *.fasta

for i in *.fasta; do awk '/>/{sub(">","&"FILENAME"_");sub(/\.fasta/,x)}1' $i >> $i.renamed; done
```

## ELSC
```{bash,  eval = FALSE}
rename 's/scaf2bin.//g' *.fasta

rename 's/^/ELSC_/g' *.fasta

for i in *.fasta; do awk '/>/{sub(">","&"FILENAME"_");sub(/\.fasta/,x)}1' $i >> $i.renamed; done
```

## EPR
```{bash,  eval = FALSE}
rename 's/scaf2bin.//g' *.fasta

rename 's/^/EPR_/g' *.fasta

for i in *.fasta; do awk '/>/{sub(">","&"FILENAME"_");sub(/\.fasta/,x)}1' $i >> $i.renamed; done
```

## Guaymas
```{bash,  eval = FALSE}
rename 's/scaf2bin.//g' *.fasta

rename 's/^/Guaymas_/g' *.fasta

for i in *.fasta; do awk '/>/{sub(">","&"FILENAME"_");sub(/\.fasta/,x)}1' $i >> $i.renamed; done
```

## MAR
```{bash,  eval = FALSE}
rename 's/scaf2bin.//g' *.fasta

rename 's/^/MAR_/g' *.fasta

for i in *.fasta; do awk '/>/{sub(">","&"FILENAME"_");sub(/\.fasta/,x)}1' $i >> $i.renamed; done
```

# Read Mapping

## EPR
```{bash,  eval = FALSE}
conda activate

nohup python3 /storage1/data14/software/mapping/mapper.py -i Assemblies_Renamed/EPR/EPR_4281-140.fasta -r /storage1/Reads/HydroVents_ZhouReysenbach/EPR/*.fastq.gz -o Read_Mapping/EPR -t 20 &

nohup python3 /storage1/data14/software/mapping/mapper.py -i Assemblies_Renamed/EPR/EPR_PIR-30.fasta -r /storage1/Reads/HydroVents_ZhouReysenbach/EPR/*.fastq.gz -o Read_Mapping/EPR -t 20 &
```

## Guaymas
```{bash,  eval = FALSE}
nohup python3 /storage1/data14/software/mapping/mapper.py -i Assemblies_Renamed/Guaymas/Guaymas_4559-240.fasta -r /storage1/Reads/HydroVents_ZhouReysenbach/Guaymas/*.fastq.gz -o Read_Mapping/Guaymas -t 20 &

nohup python3 /storage1/data14/software/mapping/mapper.py -i Assemblies_Renamed/Guaymas/Guaymas_4561-380.fasta -r /storage1/Reads/HydroVents_ZhouReysenbach/Guaymas/*.fastq.gz -o Read_Mapping/Guaymas -t 20 &

nohup python3 /storage1/data14/software/mapping/mapper.py -i Assemblies_Renamed/Guaymas/Guaymas_4561-384.fasta -r /storage1/Reads/HydroVents_ZhouReysenbach/Guaymas/*.fastq.gz -o Read_Mapping/Guaymas -t 20 &

nohup python3 /storage1/data14/software/mapping/mapper.py -i Assemblies_Renamed/Guaymas/Guaymas_4571-419.fasta -r /storage1/Reads/HydroVents_ZhouReysenbach/Guaymas/*.fastq.gz -o Read_Mapping/Guaymas -t 20 &
```

## MAR

```{bash,  eval = FALSE}
nohup python3 /storage1/data14/software/mapping/mapper.py -i Assemblies_Renamed/MAR_Lucky_356-284.fasta -r /storage1/Reads/HydroVents_ZhouReysenbach/MAR/*.fastq.gz -o Read_Mapping/MAR -t 20 &

nohup python3 /storage1/data14/software/mapping/mapper.py -i Assemblies_Renamed/MAR_Lucky_356-308.fasta -r /storage1/Reads/HydroVents_ZhouReysenbach/MAR/*.fastq.gz -o Read_Mapping/MAR -t 15 &

nohup python3 /storage1/data14/software/mapping/mapper.py -i Assemblies_Renamed/MAR_Rainbow_354-166.fasta -r /storage1/Reads/HydroVents_ZhouReysenbach/MAR/*.fastq.gz -o Read_Mapping/MAR -t 20 &

nohup python3 /storage1/data14/software/mapping/mapper.py -i Assemblies_Renamed/MAR_Rainbow_355-202.fasta -r /storage1/Reads/HydroVents_ZhouReysenbach/MAR/*.fastq.gz -o Read_Mapping/MAR -t 20 &
```

## Brothers and ELSC
Now trying with Cody's mapping wrapper
```{bash,  eval = FALSE}
conda activate

nohup python3 /storage1/data14/software/mapping/mapper.py -i AssembliesToReadsFinal.txt --batch -o Read_Mapping/BrothersELSC -rd /storage1/Reads/HydroVents_ZhouReysenbach -fd /storage1/data12/Projects/Vent_Viruses/Assemblies_Renamed -t 20 &
```

# Remove viral contamination from MAGs

BLAST all viruses against all the MAGs. You are looking for 100% matches and 100% coverage. Unless it is a lysogenic virus, it should be contamination. Just because a virus is binned with a MAG does not mean it belongs to that virus.

1. Run BLAST search
```{bash,  eval = FALSE}
cat *.fasta > All_VentMAGs.fna

makeblastdb -in All_VentMAGs.fna -title "Vent_MAGs" -dbtype nucl

nohup blastn -query  /storage1/data12/Projects/Vent_Viruses/Virus_Genomes/fna/All_Viruses.fna -db /storage1/data12/Projects/Vent_Viruses/MAGs_Renamed/Remove_ViralContam/All_VentMAGs.fna -out MAGs_Renamed/Remove_ViralContam/VirusHits_toMAGs.txt -num_threads 20 -outfmt "6 qseqid length qlen slen pident bitscore stitle" &
```

2. Filter blast hits and subset from MAGs
```{bash,  eval = FALSE}
python3 /storage1/data12/scripts/filter_blast_100c_pi.py VirusHits_toMAGs.txt VirusHits_toMAGs_filtered.txt

cut -f7 VirusHits_toMAGs_filtered.txt > Viral_Contam.txt

for i in *.fasta; do perl /storage1/data12/scripts/screen_list_new.pl Remove_ViralContam/Viral_Contam.txt $i >> Remove_ViralContam/$i.noVirusContam.fna; done

cat *noVirusContam* > All_VentMAGs_noViralContam.fna
```

# ViWrap
**Unfortunately this ended up not being an option because it would take a month to run through all my samples. One smaller scale sample took 10 hours, times 42 samples = inefficient.**

Testing ViWrap - it would be nice if I could use it to get all the output I need :)

## Brothers Diffuse
```{bash,  eval = FALSE}
conda activate /storage1/data22/ViWrap_conda_environments/ViWrap

ViWrap run --input_metagenome /storage1/data12/Projects/Vent_Viruses/Assemblies_Renamed/Brothers_Volcano/Brothers_Diffuse_S009_metaspades_scaffolds.min1000.fasta \
               --input_reads /storage1/Reads/HydroVents_ZhouReysenbach/Brothers_Volcano/Diffuse_Flow/lane2-s009-indexN705-S505-GGACTCCT-CTCCTTAC-279_debarcode_1.fastq.gz,/storage1/Reads/HydroVents_ZhouReysenbach/Brothers_Volcano/Diffuse_Flow/lane2-s009-indexN705-S505-GGACTCCT-CTCCTTAC-279_debarcode_2.fastq.gz,/storage1/Reads/HydroVents_ZhouReysenbach/Brothers_Volcano/Diffuse_Flow/lane4-s015-indexN703-S517-AGGCAGAA-TCTTACGC-Green_debarcode_1.fastq.gz,/storage1/Reads/HydroVents_ZhouReysenbach/Brothers_Volcano/Diffuse_Flow/lane4-s015-indexN703-S517-AGGCAGAA-TCTTACGC-Green_debarcode_2.fastq.gz \
               --input_reads_type illumina \
               --reads_mapping_identity_cutoff 0.97 \
               --out_dir /storage1/data12/Projects/Vent_Viruses/ViWrap/Brothers_Diffuse \
               --db_dir /storage1/data22/ViWrap/ViWrap_db \
               --identify_method  vb \
               --conda_env_dir /storage1/data22/ViWrap_conda_environments \
               --threads 20 \
               --input_length_limit 2000 \
               --custom_MAGs_dir /storage1/data12/Projects/Vent_Viruses/MAGs_Renamed/Remove_ViralContam/Brothers/Diffuse
               

nohup ./bash_BD.sh &
```

I decided to leave off the custom MAG option for iphop since that takes a lot of time. I can take all the viruses and all the MAGs and run that on my own after I have all the vMAGs and unbinned viruses.

```{bash,  eval = FALSE}
conda activate /storage1/data22/ViWrap_conda_environments/ViWrap

ViWrap run --input_metagenome /storage1/data12/Projects/Vent_Viruses/Assemblies_Renamed/Brothers_Volcano/Brothers_Diffuse_S015_metaspades_scaffolds.min1000.fasta \
               --input_reads /storage1/Reads/HydroVents_ZhouReysenbach/Brothers_Volcano/Diffuse_Flow/lane2-s009-indexN705-S505-GGACTCCT-CTCCTTAC-279_debarcode_1.fastq.gz,/storage1/Reads/HydroVents_ZhouReysenbach/Brothers_Volcano/Diffuse_Flow/lane2-s009-indexN705-S505-GGACTCCT-CTCCTTAC-279_debarcode_2.fastq.gz,/storage1/Reads/HydroVents_ZhouReysenbach/Brothers_Volcano/Diffuse_Flow/lane4-s015-indexN703-S517-AGGCAGAA-TCTTACGC-Green_debarcode_1.fastq.gz,/storage1/Reads/HydroVents_ZhouReysenbach/Brothers_Volcano/Diffuse_Flow/lane4-s015-indexN703-S517-AGGCAGAA-TCTTACGC-Green_debarcode_2.fastq.gz \
               --input_reads_type illumina \
               --reads_mapping_identity_cutoff 0.97 \
               --out_dir /storage1/data12/Projects/Vent_Viruses/ViWrap/Brothers_Diffuse_S015 \
               --db_dir /storage1/data22/ViWrap/ViWrap_db \
               --identify_method  vb \
               --conda_env_dir /storage1/data22/ViWrap_conda_environments \
               --threads 20 \
               --input_length_limit 2000
               

nohup ./bash_BD_S015.sh &
```

## Running ViWrap using Cody's wrapper

```{bash,  eval = FALSE}
conda activate

nohup python3 /storage1/data14/for_maggie/ViWrap_loop.py -s AssembliesToReads_ViWrap.txt -a /storage1/data12/Projects/Vent_Viruses/Assemblies_Renamed/ -r /storage1/Reads/HydroVents_ZhouReysenbach/ &
```





# vRhyme Binning

Don't judge me for running this one by one...I was doing it as the bam files were coming out from the read mapping because I'm impatient :)

## EPR
```{bash,  eval = FALSE}
conda activate vRhyme

vRhyme -i VIBRANT_output/VIBRANT_EPR_4281-140/VIBRANT_phages_EPR_4281-140/EPR_4281-140.phages_combined.fna -b Read_Mapping/EPR/EPR_4281-140/*.bam -t 5

vRhyme -i VIBRANT_output/VIBRANT_EPR_PIR-30/VIBRANT_phages_EPR_PIR-30/EPR_PIR-30.phages_combined.fna -b Read_Mapping/EPR/EPR_PIR-30/*.bam -t 5
```

## Guaymas
```{bash,  eval = FALSE}
conda activate vRhyme

vRhyme -i VIBRANT_output/VIBRANT_Guaymas_4559-240/VIBRANT_phages_Guaymas_4559-240/Guaymas_4559-240.phages_combined.fna   -b Read_Mapping/Guaymas/Guaymas_4559-240/*.bam -t 5

vRhyme -i VIBRANT_output/VIBRANT_Guaymas_4561-380/VIBRANT_phages_Guaymas_4561-380/Guaymas_4561-380.phages_combined.fna  -b Read_Mapping/Guaymas/Guaymas_4561-380/*.bam -t 5

vRhyme -i VIBRANT_output/VIBRANT_Guaymas_4561-384/VIBRANT_phages_Guaymas_4561-384/Guaymas_4561-384.phages_combined.fna -b Read_Mapping/Guaymas/Guaymas_4561-384/*.bam -t 5

vRhyme -i VIBRANT_output/VIBRANT_Guaymas_4571-419/VIBRANT_phages_Guaymas_4571-419/Guaymas_4571-419.phages_combined.fna  -b Read_Mapping/Guaymas/Guaymas_4571-419/*.bam -t 5
```

## MAR
```{bash,  eval = FALSE}
conda activate vRhyme

vRhyme -i VIBRANT_output/VIBRANT_MAR_Lucky_356-284/VIBRANT_phages_MAR_Lucky_356-284/MAR_Lucky_356-284.phages_combined.fna  -b Read_Mapping/MAR/MAR_Lucky_356-284/*.bam -t 5

vRhyme -i VIBRANT_output/VIBRANT_MAR_Lucky_356-308/VIBRANT_phages_MAR_Lucky_356-308/MAR_Lucky_356-308.phages_combined.fna -b Read_Mapping/MAR/MAR_Lucky_356-308/*.bam -t 5

vRhyme -i VIBRANT_output/VIBRANT_MAR_Rainbow_354-166/VIBRANT_phages_MAR_Rainbow_354-166/MAR_Rainbow_354-166.phages_combined.fna -b Read_Mapping/MAR/MAR_Rainbow_354-166/*.bam -t 5

vRhyme -i VIBRANT_output/VIBRANT_MAR_Rainbow_355-202/VIBRANT_phages_MAR_Rainbow_355-202/MAR_Rainbow_355-202.phages_combined.fna -b Read_Mapping/MAR/MAR_Rainbow_355-202/*.bam -t 5
```



## Brothers
### Diffuse
```{bash,  eval = FALSE}
conda activate vRhyme

vRhyme -i VIBRANT_output/VIBRANT_Brothers_Diffuse_S009_metaspades_scaffolds.min1000/VIBRANT_phages_Brothers_Diffuse_S009_metaspades_scaffolds.min1000/Brothers_Diffuse_S009_metaspades_scaffolds.min1000.phages_combined.fna -b Read_Mapping/BrothersELSC/Brothers_Diffuse_S009* -t 5

vRhyme -i VIBRANT_output/VIBRANT_Brothers_Diffuse_S015_metaspades_scaffolds.min1000/VIBRANT_phages_Brothers_Diffuse_S015_metaspades_scaffolds.min1000/Brothers_Diffuse_S015_metaspades_scaffolds.min1000.phages_combined.fna -b Read_Mapping/BrothersELSC/Brothers_Diffuse_S015/*bam -t 5
```

### LC
```{bash,  eval = FALSE}
vRhyme -i VIBRANT_output/VIBRANT_Brothers_LC_S014_metaspades_scaffolds.min1000/VIBRANT_phages_Brothers_LC_S014_metaspades_scaffolds.min1000/Brothers_LC_S014_metaspades_scaffolds.min1000.phages_combined.fna -b Read_Mapping/BrothersELSC/Brothers_LC_S014/*bam -t 5

vRhyme -i VIBRANT_output/VIBRANT_Brothers_LC_S016_metaspades_scaffolds.min1000/VIBRANT_phages_Brothers_LC_S016_metaspades_scaffolds.min1000/Brothers_LC_S016_metaspades_scaffolds.min1000.phages_combined.fna -b Read_Mapping/BrothersELSC/Brothers_LC_S016/*bam -t 5
```

### NWCA
```{bash,  eval = FALSE}
vRhyme -i VIBRANT_output/VIBRANT_Brothers_NWCA_S013_metaspades_scaffolds.min1000/VIBRANT_phages_Brothers_NWCA_S013_metaspades_scaffolds.min1000/Brothers_NWCA_S013_metaspades_scaffolds.min1000.phages_combined.fna -b Read_Mapping/BrothersELSC/Brothers_NWCA_S013/*bam -t 5

vRhyme -i VIBRANT_output/VIBRANT_Brothers_NWCA_S017_metaspades_scaffolds.min1000/VIBRANT_phages_Brothers_NWCA_S017_metaspades_scaffolds.min1000/Brothers_NWCA_S017_metaspades_scaffolds.min1000.phages_combined.fna -b Read_Mapping/BrothersELSC/Brothers_NWCA_S017/*bam -t 5

vRhyme -i VIBRANT_output/VIBRANT_Brothers_NWCA_S142_metaspades_scaffolds.min1000/VIBRANT_phages_Brothers_NWCA_S142_metaspades_scaffolds.min1000/Brothers_NWCA_S142_metaspades_scaffolds.min1000.phages_combined.fna -b Read_Mapping/BrothersELSC/Brothers_NWCA_S142/*bam -t 5

vRhyme -i VIBRANT_output/VIBRANT_Brothers_NWCA_S143_metaspades_scaffolds.min1000/VIBRANT_phages_Brothers_NWCA_S143_metaspades_scaffolds.min1000/Brothers_NWCA_S143_metaspades_scaffolds.min1000.phages_combined.fna -b Read_Mapping/BrothersELSC/Brothers_NWCA_S143/*bam -t 5

vRhyme -i VIBRANT_output/VIBRANT_Brothers_NWCA_S144_metaspades_scaffolds.min1000/VIBRANT_phages_Brothers_NWCA_S144_metaspades_scaffolds.min1000/Brothers_NWCA_S144_metaspades_scaffolds.min1000.phages_combined.fna -b Read_Mapping/BrothersELSC/Brothers_NWCA_S144/*bam -t 5

vRhyme -i VIBRANT_output/VIBRANT_Brothers_NWCA_S145_metaspades_scaffolds.min1000/VIBRANT_phages_Brothers_NWCA_S145_metaspades_scaffolds.min1000/Brothers_NWCA_S145_metaspades_scaffolds.min1000.phages_combined.fna -b Read_Mapping/BrothersELSC/Brothers_NWCA_S145/*bam -t 5
```


### NWCB
```{bash,  eval = FALSE}
vRhyme -i VIBRANT_output/VIBRANT_Brothers_NWCB_S012_metaspades_scaffolds.min1000/VIBRANT_phages_Brothers_NWCB_S012_metaspades_scaffolds.min1000/Brothers_NWCB_S012_metaspades_scaffolds.min1000.phages_combined.fna -b Read_Mapping/BrothersELSC/Brothers_NWCB_S012/*bam -t 5

vRhyme -i VIBRANT_output/VIBRANT_Brothers_NWCB_S139_metaspades_scaffolds.min1000/VIBRANT_phages_Brothers_NWCB_S139_metaspades_scaffolds.min1000/Brothers_NWCB_S139_metaspades_scaffolds.min1000.phages_combined.fna -b Read_Mapping/BrothersELSC/Brothers_NWCB_S139/*bam -t 5

vRhyme -i VIBRANT_output/VIBRANT_Brothers_NWCB_S140_metaspades_scaffolds.min1000/VIBRANT_phages_Brothers_NWCB_S140_metaspades_scaffolds.min1000/Brothers_NWCB_S140_metaspades_scaffolds.min1000.phages_combined.fna -b Read_Mapping/BrothersELSC/Brothers_NWCB_S140/*bam -t 5

vRhyme -i VIBRANT_output/VIBRANT_Brothers_NWCB_S141_metaspades_scaffolds.min1000/VIBRANT_phages_Brothers_NWCB_S141_metaspades_scaffolds.min1000/Brothers_NWCB_S141_metaspades_scaffolds.min1000.phages_combined.fna -b Read_Mapping/BrothersELSC/Brothers_NWCB_S141/*bam -t 5

vRhyme -i VIBRANT_output/VIBRANT_Brothers_NWCB_S146_metaspades_scaffolds.min1000/VIBRANT_phages_Brothers_NWCB_S146_metaspades_scaffolds.min1000/Brothers_NWCB_S146_metaspades_scaffolds.min1000.phages_combined.fna -b Read_Mapping/BrothersELSC/Brothers_NWCB_S146/*bam -t 5
```

### UC
```{bash,  eval = FALSE}
vRhyme -i VIBRANT_output/VIBRANT_Brothers_UC_S010_metaspades_scaffolds.min1000/VIBRANT_phages_Brothers_UC_S010_metaspades_scaffolds.min1000/Brothers_UC_S010_metaspades_scaffolds.min1000.phages_combined.fna -b Read_Mapping/BrothersELSC/Brothers_UC_S010/*bam -t 5

vRhyme -i VIBRANT_output/VIBRANT_Brothers_UC_S011_metaspades_scaffolds.min1000/VIBRANT_phages_Brothers_UC_S011_metaspades_scaffolds.min1000/Brothers_UC_S011_metaspades_scaffolds.min1000.phages_combined.fna -b Read_Mapping/BrothersELSC/Brothers_UC_S011/*bam -t 5

vRhyme -i VIBRANT_output/VIBRANT_Brothers_UC_S147_metaspades_scaffolds.min1000/VIBRANT_phages_Brothers_UC_S147_metaspades_scaffolds.min1000/Brothers_UC_S147_metaspades_scaffolds.min1000.phages_combined.fna -b Read_Mapping/BrothersELSC/Brothers_UC_S147/*bam -t 5
```

### ELSC Abe
```{bash,  eval = FALSE}
vRhyme -i VIBRANT_output/VIBRANT_ELSC_Abe_128-326/VIBRANT_phages_ELSC_Abe_128-326/ELSC_Abe_128-326.phages_combined.fna -b Read_Mapping/BrothersELSC/ELSC_Abe_128-326/*bam -t 5

vRhyme -i VIBRANT_output/VIBRANT_ELSC_Abe_A1_metaspades_scaffolds.min1000/VIBRANT_phages_ELSC_Abe_A1_metaspades_scaffolds.min1000/ELSC_Abe_A1_metaspades_scaffolds.min1000.phages_combined.fna -b Read_Mapping/BrothersELSC/ELSC_Abe_A1/*bam -t 5

vRhyme -i VIBRANT_output/VIBRANT_ELSC_Abe_A3_metaspades_scaffolds.min1000/VIBRANT_phages_ELSC_Abe_A3_metaspades_scaffolds.min1000/ELSC_Abe_A3_metaspades_scaffolds.min1000.phages_combined.fna -b Read_Mapping/BrothersELSC/ELSC_Abe_A3/*bam -t 5
```
### ELSC Mariner
```{bash,  eval = FALSE}
vRhyme -i VIBRANT_output/VIBRANT_ELSC_Bowl_M1_metaspades_scaffolds.min1000/VIBRANT_phages_ELSC_Bowl_M1_metaspades_scaffolds.min1000/ELSC_Bowl_M1_metaspades_scaffolds.min1000.phages_combined.fna -b Read_Mapping/BrothersELSC/ELSC_Bowl_M1/*bam -t 5

vRhyme -i VIBRANT_output/VIBRANT_ELSC_Bowl_M2_metaspades_scaffolds.min1000/VIBRANT_phages_ELSC_Bowl_M2_metaspades_scaffolds.min1000/ELSC_Bowl_M2_metaspades_scaffolds.min1000.phages_combined.fna -b Read_Mapping/BrothersELSC/ELSC_Bowl_M2/*bam -t 5

vRhyme -i VIBRANT_output/VIBRANT_ELSC_Mariner_131-447/VIBRANT_phages_ELSC_Mariner_131-447/ELSC_Mariner_131-447.phages_combined.fna -b Read_Mapping/BrothersELSC/ELSC_Mariner_131-447/*bam -t 5

vRhyme -i VIBRANT_output/VIBRANT_ELSC_Mariner_M10_metaspades_scaffolds.min1000/VIBRANT_phages_ELSC_Mariner_M10_metaspades_scaffolds.min1000/ELSC_Mariner_M10_metaspades_scaffolds.min1000.phages_combined.fna -b Read_Mapping/BrothersELSC/ELSC_Mariner_M10/*bam -t 5

vRhyme -i VIBRANT_output/VIBRANT_ELSC_Mariner_M17_metaspades_scaffolds.min1000/VIBRANT_phages_ELSC_Mariner_M17_metaspades_scaffolds.min1000/ELSC_Mariner_M17_metaspades_scaffolds.min1000.phages_combined.fna -b Read_Mapping/BrothersELSC/ELSC_Mariner_M17/*bam -t 5
```

```{bash,  eval = FALSE}
vRhyme -i VIBRANT_output/VIBRANT_ELSC_Abe_128-326/VIBRANT_phages_ELSC_Abe_128-326/ELSC_Abe_128-326.phages_combined.fna -b Read_Mapping/BrothersELSC/ELSC_Abe_128-326/*bam -t 5

vRhyme -i VIBRANT_output/VIBRANT_ELSC_Abe_A1_metaspades_scaffolds.min1000/VIBRANT_phages_ELSC_Abe_A1_metaspades_scaffolds.min1000/ELSC_Abe_A1_metaspades_scaffolds.min1000.phages_combined.fna -b Read_Mapping/BrothersELSC/ELSC_Abe_A1/*bam -t 5

vRhyme -i VIBRANT_output/VIBRANT_ELSC_Abe_A3_metaspades_scaffolds.min1000/VIBRANT_phages_ELSC_Abe_A3_metaspades_scaffolds.min1000/ELSC_Abe_A3_metaspades_scaffolds.min1000.phages_combined.fna -b Read_Mapping/BrothersELSC/ELSC_Abe_A3/*bam -t 5
```


### ELSC Tui Malila
```{bash,  eval = FALSE}
vRhyme -i VIBRANT_output/VIBRANT_ELSC_Tui_Malila_132-544/VIBRANT_phages_ELSC_Tui_Malila_132-544/ELSC_Tui_Malila_132-544.phages_combined.fna -b Read_Mapping/BrothersELSC/ELSC_Tui_Malila_132-544/*bam -t 5

vRhyme -i VIBRANT_output/VIBRANT_ELSC_Tui_Malila_134-614/VIBRANT_phages_ELSC_Tui_Malila_134-614/ELSC_Tui_Malila_134-614.phages_combined.fna -b Read_Mapping/BrothersELSC/ELSC_Tui_Malila_134-614/*bam -t 5

vRhyme -i VIBRANT_output/VIBRANT_ELSC_Tui_Malila_T10_metaspades_scaffolds.min1000/VIBRANT_phages_ELSC_Tui_Malila_T10_metaspades_scaffolds.min1000/ELSC_Tui_Malila_T10_metaspades_scaffolds.min1000.phages_combined.fna -b Read_Mapping/BrothersELSC/ELSC_Tui_Malila_T10/*bam -t 5

vRhyme -i VIBRANT_output/VIBRANT_ELSC_Tui_Malila_T11_metaspades_scaffolds.min1000/VIBRANT_phages_ELSC_Tui_Malila_T11_metaspades_scaffolds.min1000/ELSC_Tui_Malila_T11_metaspades_scaffolds.min1000.phages_combined.fna -b Read_Mapping/BrothersELSC/ELSC_Tui_Malila_T11/*bam -t 5

vRhyme -i VIBRANT_output/VIBRANT_ELSC_Tui_Malila_T2_metaspades_scaffolds.min1000/VIBRANT_phages_ELSC_Tui_Malila_T2_metaspades_scaffolds.min1000/ELSC_Tui_Malila_T2_metaspades_scaffolds.min1000.phages_combined.fna -b Read_Mapping/BrothersELSC/ELSC_Tui_Malila_T2/*bam -t 5
```

### Vai Lili
```{bash,  eval = FALSE}
vRhyme -i VIBRANT_output/VIBRANT_ELSC_Vai_Lili_V2_metaspades_scaffolds.min1000/VIBRANT_phages_ELSC_Vai_Lili_V2_metaspades_scaffolds.min1000/ELSC_Vai_Lili_V2_metaspades_scaffolds.min1000.phages_combined.fna -b Read_Mapping/BrothersELSC/ELSC_Vai_Lili_V2/*bam -t 5
```


# Renaming vMAGs
```{bash,  eval = FALSE}
mkdir originals_vMAGs
```

1. Run bash script with the following contents to find vMAGs, rename them, cp them 1 dir up:
```{bash,  eval = FALSE}
./rename_vMAGs.sh

#!/bin/bash

find . -maxdepth 3 -type f -name "*fasta" -exec sh -c '
  for img; do
    parentdir=${img%/*/*}      # leave the parent dir (remove the last `/` and filename)
    dirname=${parentdir##*/} # leave the parent directory name (remove all parent paths `*/`)
    cp -i "$img" "$parentdir/${dirname}_${img##*/}"
  done
' sh {} +
```

2. Find renamed vMAGs, put them in 1 folder, clean up the names
```{bash,  eval = FALSE}
find -maxdepth 2 -name "*.fasta" | xargs -i mv {} fna/

rename 's/vRhyme_results_//' *.fasta
rename 's/.phages_combined//' *.fasta
rename 's/_metaspades_scaffolds.min1000//' *.fasta
```

# Use vRhyme to get the N-linked scaffolds of vMAGs
You'll need this to run CheckV, iphop, and other programs on the vMAGs

```{bash,  eval = FALSE}
conda activate vRhyme

link_bin_sequences.py -i fna/ -o fna_Nlinked_scaffolds
```

# Get a file of unbinned viruses for the same 42 samples

1. Concatenate the viruses into 1 file
```{bash,  eval = FALSE}
cat *fasta > ../all_vMAGs.fna
```

2. Make a mapping file to use in the future for mapping vMAG file name: scaffold names
```{bash,  eval = FALSE}
grep ">" *.fasta | sed 's/:>/\t/g' | sed 's/.fasta/\t/g' | cut -f1,3 | sed 's/__/\t/g' | cut -f1,3 > ../vMAG_scaffold_mapping.txt

cut -f2 vMAG_scaffold_mapping.txt > binned_viral_scaffolds.txt
```

3. Subset the file of all viruses for unbinned viruses using the txt file of binned viral scaffolds
```{bash,  eval = FALSE}
screen_list_new.pl ../../../vRhyme/binned_viral_scaffolds.txt All_Viruses.fna > unbinned_VentViruses.fna
```

# Run iphop on the vUnbinned and vMAGs
Run iphop on the 1500N-concatenated vMAGs and unbinned viruses so you can compare host predictions with the plume viruses.

**If you're doing this again, do step 2 first if you anticipate any illegal characters in your MAGs. Then proceed**

First, make a custom iphop database using the MAGs from the 42 vents
1. Run gtdbtk 1.5.0 on the MAGs
```{bash,  eval = FALSE}
conda activate gtdbtk-1.5.0

nohup gtdbtk de_novo_wf --genome_dir MAGs_Renamed/No_ViralContam/ --bacteria --outgroup_taxon p__Bdellovibrionota --out_dir Vent_MAGs_gtdbtk_denovo_wf/ --cpus 20 --force --extension fna &

nohup gtdbtk de_novo_wf --genome_dir MAGs_Renamed/No_ViralContam/ --archaea --outgroup_taxon p__Altarchaeota --out_dir Vent_MAGs_gtdbtk_denovo_wf/ --cpus 20 --force --extension fna &
```

2. Create iphop database. I ran into the same problem that James did where iphop complained about illegal characters so I'm going to follow his steps to fix it. In the second command we are running iphop predict with the MAGs as the input viruses to get the "cleaned file" since my MAGs are giving me errors for illegal characters. Then use the split_MAGs.py script to split up the MAGs back into individual files.
```{bash,  eval = FALSE}
conda activate iphop

nohup iphop predict --fa_file MAGs_Renamed/All_VentMAGs_noViralContam.fna --out_dir clean_iphop_MAGs --db_dir /storage1/databases/iPHoP/Sept_2021_pub/ --num_threads 20 &

python3 split_MAGs.py
```

3. Rerun GTDBtk stuff with new names/cleaned MAGs. Remember the outgroups should be something you do not have in your dataset. So remember to check the GTDBtk taxonomy of your MAGs, then choose an outgroup that is distant.
```{bash,  eval = FALSE}
conda activate gtdbtk-1.5.0

nohup gtdbtk de_novo_wf --genome_dir clean_iphop_MAGs/clean_fnas/ --bacteria --outgroup_taxon p__Bdellovibrionota --out_dir Vent_MAGs_gtdbtk_denovo_wf_clean/ --cpus 20 &

nohup gtdbtk de_novo_wf --genome_dir clean_iphop_MAGs/clean_fnas/ --archaea --outgroup_taxon p__Huberarchaeota --out_dir Vent_MAGs_gtdbtk_denovo_wf_clean/ --cpus 20 &
```

4. Add MAGs finally to iphop db
```{bash,  eval = FALSE}
nohup iphop add_to_db --fna_dir clean_iphop_MAGs/clean_fnas/ --gtdb_dir Vent_MAGs_gtdbtk_denovo_wf_clean/ --out_dir iPHoP_Sept_2021_w_VentMAGs --db_dir /storage1/databases/iPHoP/Sept_2021_pub/ &
```

5. Run iphop using your custom database
```{bash,  eval = FALSE}
nohup iphop predict --fa_file Virus_Genomes/fna/vUnbinned_vMAG_1500Ns_VentViruses.fna --db_dir iPHoP_Sept_2021_w_VentMAGs/ --out_dir iphop/iphop_vUnbinned_vMAG_1500Ns_MAGdb -t 20 --no_qc &
```

# Collect the VIBRANT output into single files
```{bash,  eval = FALSE}
find VIBRANT* -name "*AMG_individuals*" | xargs -i cp {} AMG_VIBRANT_output/AMG_individuals/

find VIBRANT* -name "*AMG_counts*" | xargs -i cp {} AMG_VIBRANT_output/AMG_counts/

find VIBRANT* -name "*annotations*" | xargs -i cp {} AMG_VIBRANT_output/AMG_counts/

find VIBRANT* -name "*genome_quality*" | xargs -i cp {} Quality_VIBRANT_output/
```

# Run CheckV on the vMAGs

```{bash, eval = FALSE}
nohup checkv end_to_end Virus_Genomes/fna/all_vMAGs_1500Ns.fna CheckV_vMAGs -t 20 &
```

## Make a file of unbinned CheckV results

```{bash, eval = FALSE}
screen_list_new.pl ../vRhyme/binned_viral_scaffolds.txt quality_summary.tsv > quality_summary_vUnbinned_Vents.tsv
```
I ended up doing this quickly with vlookup in excel because this was not behaving as expected/not working

# Rename the faa vMAG files

1. Modify the bash script to find the faa vMAGs
```{bash, eval = FALSE}
./rename_vMAGs.sh

#!/bin/bash

find . -maxdepth 3 -type f -name "*[0-9].faa" -exec sh -c '
  for img; do
    parentdir=${img%/*/*}      # leave the parent dir (remove the last `/` and filename)
    dirname=${parentdir##*/} # leave the parent directory name (remove all parent paths `*/`)
    cp -i "$img" "$parentdir/${dirname}_${img##*/}"
  done
' sh {} +
```

2. Mv them to 1 dir
```{bash, eval = FALSE}
find -maxdepth 2 -name "*[0-9].faa" | xargs -i mv {} /storage1/data12/Projects/Vent_Viruses/vRhyme/faa/
```

3. Clean up the names
```{bash, eval = FALSE}
rename 's/vRhyme_results_//' *.faa
rename 's/.phages_combined//' *.faa
rename 's/_metaspades_scaffolds.min1000//' *.faa
```

# Clustering
## Using skani to compare ANI between viruses

This utilizes a skani-vMAG.py script written by Cody.
```{bash, eval = FALSE}
conda install -c bioconda skani

nohup /storage1/data14/software/skani-vMAG/python/skani-vMAG.py -c ../Virus_Genomes/fna/unbinned_VentViruses.fna -d ../vRhyme/fna -x .fasta --outdir . &
```

## Cluster the skani results using mcl

1. Preprocess the file using polars. This utilizes preprocess.py written by Cody.
```{bash, eval = FALSE}
conda create --name mcl
conda install -c "bioconda/label/cf201901" mcl
conda install -c conda-forge polars

/storage1/data14/software/skani-vMAG/python/preprocess.py -i skani_output_vUnbinned_vMAGs_Vents.tsv -o skani_PreprocessedOutput_vUnbinned_vMAGs_Vents.tsv
```

2. Pass the preprocessed file to mcxload
```{bash, eval = FALSE}
mcxload -abc skani/skani_PreprocessedOutput_vUnbinned_vMAGs_Vents.tsv -o mcl_clusters/vUnbinned_vMAGs_Vents.mci -write-tab mcl_clusters/vUnbinned_vMAGs_Vents.mcxload
```

3. Then to mcl
```{bash, eval = FALSE}
nohup mcl vUnbinned_vMAGs_Vents.mci -use-tab vUnbinned_vMAGs_Vents.mcxload -o out_vUnbinned_vMAGs_Vents.clusters &
```
That pipeline seems to work and I get 2,574 clusters. That seems reasonable for 31,136 viruses. The clusters look mixed by vent.

## ANI clustering with skani and mcl using both Vent and Plume data

1. Compare ANI using skani
```{bash, eval = FALSE}
conda activate

nohup /storage1/data14/software/skani-vMAG/python/skani-vMAG.py -c fna_vUnbinned/unbinned_PlumeVent_viruses.fna -d fna_vMAGs -x .fasta --outdir . -o skani_ANI_vUnbinned_vMAGs_PlumeVents.tsv &
```

2. Preprocess
```{bash, eval = FALSE}
/storage1/data14/software/skani-vMAG/python/preprocess.py -i ../../skani/PlumeVent/skani_ANI_vUnbinned_vMAGs_PlumeVents.tsv -o skani_ANI_vUnbinned_vMAGs_PlumeVents_processed.tsv
```

3. MCL
```{bash, eval = FALSE}
conda activate mcl

mcxload -abc skani_ANI_vUnbinned_vMAGs_PlumeVents_processed.tsv -o vUnbinned_vMAGs_PlumeVents.mci -write-tab vUnbinned_vMAGs_PlumeVents.mcxload

nohup mcl vUnbinned_vMAGs_PlumeVents.mci -use-tab vUnbinned_vMAGs_PlumeVents.mcxload -o vUnbinned_vMAGs_PlumeVents.clusters &
```
This produced 3,294 clusters from 38,014 viruses

4. Analyze cluster output
First convert file to comma separated for easier data wrangling.
```{bash, eval = FALSE}
sed 's/\t/,/g' vUnbinned_vMAGs_PlumeVents.clusters > vUnbinned_vMAGs_PlumeVents.clusters.csv
```

Grab only comma separated lines to see how many clusters excluding singletons.
```{bash, eval = FALSE}
grep "," vUnbinned_vMAGs_PlumeVents.clusters.csv > vUnbinned_vMAGs_PlumeVents.clusters_noSingletons.csv

cat vUnbinned_vMAGs_PlumeVents.clusters_noSingletons.csv | wc
```
**2,797 clusters with 2 or more viral genomes. 497 viral genomes are singletons**

### To reformat mcl cluster table so that vRhyme MAG names are in the right format

```{bash, eval = FALSE}
cut -f1,2 mcl_formatted_table_VentPlumeViruses.tsv | sort | sed 's/__/\t/g' | sed 's/vRhyme_/vRhyme_bin_/g' | sed 's/_k95/\t/g' | sed 's/_NODE/\t/g' | sed 's/_scaffold/\t/g' | grep "vRhyme" | cut -f1,2,3 | awk '{ print $1 " " $3 "_" $2}' > mcl_vMAGs_renamed.txt
```
**Used this to create mcl_formatted_table_VentPlumeViruses_renamedFinal, which is the final mcl cluster file with the right names for all 1kb viruses from Plume and Vent**

### Redoing mcl clustering of 1kb PlumeVent skani output for higher aligned fraction

1. To only get output for viral genomes where aligned fraction is >50%
```{bash, eval = FALSE}
awk '{ if ($4 >= 50 && $5 >= 50) print $1 "\t" $2 "\t" $3 "\t" $4 "\t" $5 "\t" $6 "\t" $7 }' skani_ANI_vUnbinned_vMAGs_PlumeVents.tsv > skani_ANI_vUnbinned_vMAGs_PlumeVents_50AF.tsv
```

2. Preprocess that file - I had to do this on sulfur because needed polars from mcl conda environment. Remember has to be older version if you're getting the error about sep vs separation
```{bash, eval = FALSE}
/storage1/data14/software/skani-vMAG/python/preprocess.py -i skani_ANI_vUnbinned_vMAGs_PlumeVents_50AF.tsv -o skani_ANI_vUnbinned_vMAGs_PlumeVents_50AF_processed.tsv
```
**Notice that lowest value from this processed file is much higher than the lowest from the old processed file**

3. Run mcxload
```{bash, eval = FALSE}
mcxload -abc skani_ANI_vUnbinned_vMAGs_PlumeVents_50AF_processed.tsv -o mcl/vUnbinned_vMAGs_PlumeVents_50AF.mci -write-tab mcl/vUnbinned_vMAGs_PlumeVents_50AF.mcxload
```

4. Run mcl
```{bash, eval = FALSE}
mcl vUnbinned_vMAGs_PlumeVents_50AF.mci -use-tab vUnbinned_vMAGs_PlumeVents_50AF.mcxload -o out_vUnbinned_vMAGs_PlumeVents_50AF.clusters
```
1,021 clusters found

5. Convert to csv
```{bash, eval = FALSE}
sed 's/\t/,/g' out_vUnbinned_vMAGs_PlumeVents_50AF.clusters > out_vUnbinned_vMAGs_PlumeVents_50AF.clusters.csv
```

## Final clustering with skani and mcl, Vent and Plume, 5kb and above viruses

1. Set up directories of viral genomes by creating sym links for vMAGs >=5kb. Also get 1 file of unbinned viruses >5kb. Remember to replace "=" in name to "_" because of issues.
```{bash, eval = FALSE}
pwd
/storage1/data12/Projects/Vent_Viruses/mcl_clusters/PlumeVent_5kb

sed 's/$/.fasta/g' 5kb_AllViruses_list.txt > 5kb_PlumeVentViruses_list_noEqual.txt
sed -i 's/=/_/g' 5kb_PlumeVentViruses_list_noEqual.txt
grep "vRhyme" 5kb_PlumeVentViruses_list_noEqual.txt > 5kb_PlumeVentViruses_list_vMAGsOnly.txt

for i in `cat 5kb_PlumeVentViruses_list_vMAGsOnly.txt`; do ln -s /storage1/data12/Projects/Vent_Viruses/dRep/input_viruses_fna/$i fna_vMAGs/; done

perl screen_list_new.pl 5kb_vUnbinned.txt unbinned_PlumeVentViruses.fna keep > vUnbinned_PlumeVent_Viruses_5kb.fna
```

2. Rerun ANI with skani
```{bash, eval = FALSE}
conda activate

nohup /storage1/data14/software/skani-vMAG/python/skani-vMAG.py -c vUnbinned_PlumeVent_Viruses_5kb.fna -d /storage1/data12/Projects/Vent_Viruses/mcl_clusters/PlumeVent_5kb/fna_vMAGs -x .fasta --outdir . &

cp skani_ANI.tsv skani_ANI_PlumeVent_Viruses_5kb.tsv
```

3. Preprocess the skani ANI results to cluster with mcl
```{bash, eval = FALSE}
conda activate mcl

/storage1/data14/software/skani-vMAG/python/preprocess.py -i skani_ANI_PlumeVent_Viruses_5kb.tsv -o skani_ANIprocessed_PlumeVent_Viruses_5kb.tsv
```

4. Run clustering with mcl
```{bash, eval = FALSE}
conda activate mcl

mcxload -abc skani_ANIprocessed_PlumeVent_Viruses_5kb.tsv -o PlumeVent_Viruses_5kb.mci -write-tab PlumeVent_Viruses_5kb.mcxload

nohup mcl PlumeVent_Viruses_5kb.mci -use-tab PlumeVent_Viruses_5kb.mcxload -o PlumeVent_Viruses_5kb.clusters &

sed 's/\t/,/g' PlumeVent_Viruses_5kb.clusters > PlumeVent_Viruses_5kb.clusters.csv
```

## Redoing skani with only sulfur cycling viruses

1. Rerun skani on just sulfur cycling viruses (on Sulfur)
```{bash, eval = FALSE}
nohup /storage1/data14/software/skani-vMAG/python/skani-vMAG.py -c sulfur_vUnbinned.fna -d VirusGenomes/vMAGs/ -x .fasta --outdir . &

mv skani_ANI.tsv skani_ANI_VentPlume_sulfurViruses.tsv

/storage1/data14/software/skani-vMAG/python/preprocess.py -i skani_ANI_VentPlume_sulfurViruses.tsv -o skani_ANI_VentPlume_sulfurViruses_processed.tsv
```

2. Filter for >50AF
```{bash, eval = FALSE}
awk '{ if ($4 >= 50 && $5 >= 50) print $1 "\t" $2 "\t" $3 "\t" $4 "\t" $5 "\t" $6 "\t" $7 }' skani_ANI_VentPlume_sulfurViruses.tsv > skani_ANI_VentPlume_sulfurViruses_50AF.tsv
```

3. Also preprocess the sulfur only viruses ANI with AF50
```{bash, eval = FALSE}
/storage1/data14/software/skani-vMAG/python/preprocess.py -i skani_ANI_VentPlume_sulfurViruses_50AF.tsv -o skani_ANI_VentPlume_sulfurViruses_50AF_processed.tsv
```
**This made me realize the problem with skani triangle is it won't filter by AF. With this method I just used, I can see the ANI of sulfur viruses for those that have AF ≥50%. Do this, get the viruses, then use those in skani triangle for more accurate picture of ANI**

4. Rerun skani triangle to get the matrix for ANI plotting using new info learned. Here I am only giving it the viruses I know have an aligned fraction of ≥50 for **both** viruses, not just 1 way. You can use the --min_af option but might still get misleading results because one of the virus pairs could have low % aligned fraction.
```{bash, eval = FALSE}
skani triangle -s 80 --full-matrix --min-af 49 sulfur_genomes_for_SkaniTriangle/* > skani_ani_sulfur_FullMatrix.txt

sed 's+sulfur_genomes_for_SkaniTriangle/++g' skani_ani_sulfur_FullMatrix.txt > skani_ani_sulfur_FullMatrix_renamed.txt
```


## Clustering using dRep

1. Split the unbinned viruses into individual files. I realized I need to replace the "=" in the header name because Unix does not like it
```{bash, eval = FALSE}
splitfasta unbinned_VentViruses.fasta

for i in $(ls)
do
  name1=$(cat "$i" | grep \> | sed 's/$/.fasta/g' | sed 's/>//g')
  echo mv "$i" "${name1}"
done

./rename_script.sh
```

2. Symlink the individual virus genomes. Has to be done in a for loop because normal symlink method is too many arguments when bash is searching for the paths.
```{bash, eval = FALSE}
for i in /storage1/data12/Projects/Vent_Viruses/Virus_Genomes/fna/vUnbinned_fna/unbinned_VentViruses_split_files/*fasta; do ln -s $i .; done
```

3. Repeat for the Plume unbinned viruses. I think the "=" is a problem in the names so I am changing it to underscore for the purposes of dRep
```{bash, eval = FALSE}
sed 's/=/_/g' unbinned_PlumeViruses.fna > unbinned_PlumeViruses_renamed.fasta

splitfasta unbinned_PlumeViruses_renamed.fasta

for i in $(ls)
do
  name1=$(cat "$i" | grep \> | sed 's/$/.fasta/g' | sed 's/>//g')
  echo mv "$i" "${name1}"
done

./rename_script.sh

ln -s /storage1/data12/Projects/Plume_Viruses/Virus_Genomes/unbinned_PlumeViruses_renamed_split_files/*fasta .
```

To confirm have the expected total of viruses:
```{bash, eval = FALSE}
ls | wc -l
```
**38,014 viruses total**

4. **Nevermind, this step isn't necessary because you can ignore Genome qual**. Compile the CheckV info to provide to dRep: genome,completeness,contamination

```{bash, eval = FALSE}
cat CheckV_Output/quality_summary.tsv CheckV_vMAGs/quality_summary_vMAGs_Vents.tsv > checkV_vUnbinned_vMAGs_Vents.tsv
```

5. Run dRep dereplicate - using the guidance provided at the bottom of [this page](https://drep.readthedocs.io/en/latest/choosing_parameters.html) for clustering bacteriophages and plasmids

First, make a txt file of the paths to the vMAGs because list is too long to call with a wildcard.
```{bash, eval = FALSE}
ls > ../vMAG_paths.txt
sed -i 's+^+/storage1/data12/Projects/Vent_Viruses/dRep/input_viruses_fna/+g' vMAG_paths.txt
```

```{bash, eval = FALSE}
nohup dRep dereplicate /storage1/data12/Projects/Vent_Viruses/dRep -g vMAG_paths.txt --S_algorithm ANImf -nc .5 -l 1000 -N50W 0 -sizeW 1 --ignoreGenomeQuality --clusterAlg single -p 15 &
```
**This run with ANImf (uses nucmer to align genomes) is estimated to take ~1 week with >30k viral genomes. So I am cancelling the run and switching to fastANI. I'll probably lose some accuracy but I guess it's necessary because a week per run won't allow me to tweak parameters if necessary.**

Final command used was this:
```{bash, eval = FALSE}
/storage1/data12/miniconda3/envs/drep/bin/dRep dereplicate /storage1/data12/Projects/Vent_Viruses/dRep -g vMAG_paths.txt --S_algorithm fastANI -nc .5 -l 1000 -N50W 0 -sizeW 1 --ignoreGenomeQuality --clusterAlg single -p 15
```

6. Analyze dRep output. Use the following command to see how many representatives are in each cluster:
```{bash, eval = FALSE}
cut -d "," -f6 Cdb.csv | sort | uniq -c | sort -nr
```
14,942 clusters total.

Get the cluster ID of every cluster that has 2 or more representatives
```{bash, eval = FALSE}
cut -d "," -f6 Cdb.csv | sort | uniq -c | sort -nr | head -n1657 > ../cdb_clusterIDs_2orMore.txt
```
**There are 1,657 clusters that have 2 or more representatives. 13,285 are singletons.** 

Loop to get all the names of all the reps in a cluster
```{bash, eval = FALSE}
for i in `cat clusterIDs_toGrab.txt`; do grep -w $i Cdb.csv | cut -d "," -f1 >> $i.ViralGenomes.txt; done
```

Now add the file name to each txt file so can cat them all together
```{bash, eval = FALSE}
awk -i inplace -v ORS='\r\n' 'FNR==1{print FILENAME}1' *
```

## dRep with 5kb viruses
1. There should be 7297 viruses with genomes >5kb. Put them into 1 folder for dRep. Then make the virus genome path file
```{bash, eval = FALSE}
for i in `cat 5kb_PlumeVentViruses_list_noEqual.txt`; do cp /storage1/data12/Projects/Vent_Viruses/dRep/input_viruses_fna/$i input_VentPlume_viruses_fna_5kb/; done

ls *fasta > ../5kb_VirusGenomes_paths.txt

sed -i 's+^+/storage1/data12/Projects/Vent_Viruses/dRep/input_viruses_fna/+g' 5kb_VirusGenomes_paths.txt

sed -i 's+/storage1/data12/Projects/Vent_Viruses/dRep/input_viruses_fna/+/storage1/data12/Projects/Vent_Viruses/dRep/dRep_5kb/input_VentPlume_viruses_fna_5kb/+g' 5kb_VirusGenomes_paths.txt

```

2. Run it
```{bash, eval = FALSE}
conda activate drep

nohup /storage1/data12/miniconda3/envs/drep/bin/dRep dereplicate /storage1/data12/Projects/Vent_Viruses/dRep/dRep_5kb -g 5kb_VirusGenomes_paths.txt --S_algorithm fastANI -nc .5 -l 1000 -N50W 0 -sizeW 1 --ignoreGenomeQuality --clusterAlg single -p 15 &
```

## dRep with 5kb viruses at 90% ANI

```{bash, eval = FALSE}
conda activate drep

nohup /storage1/data12/miniconda3/envs/drep/bin/dRep dereplicate /storage1/data12/Projects/Vent_Viruses/dRep/dRep_5kb_90ani -g 5kb_VirusGenomes_paths.txt --S_algorithm fastANI -sa 0.90 -nc .5 -l 1000 -N50W 0 -sizeW 1 --ignoreGenomeQuality --clusterAlg single -p 20 --skip_plots &
```

## dRep with 1kb viruses at 90% ANI

```{bash, eval = FALSE}
nohup /storage1/data12/miniconda3/envs/drep/bin/dRep dereplicate /storage1/data12/Projects/Vent_Viruses/dRep/dRep_1kb_90ani/ -g 1kb_VirusGenomes_paths.txt --S_algorithm fastANI -sa 0.90 -nc .5 -l 1000 -N50W 0 -sizeW 1 --ignoreGenomeQuality --clusterAlg single -p 20 --skip_plots &
```

## Realized dRep has been throwing errors for some clusters

Looks like on the 5kb run, ~190 viral scaffolds are not making it into the final clustering so trying to troubleshoot errors here:
```{bash, eval = FALSE}
conda activate drep

sed 's+/dRep/input_viruses_fna+/dRep/dRep_1kb/input_viruses_fna+g' vMAG_paths.txt > ../1kb_VirusGenomes_paths.txt

nohup /storage1/data12/miniconda3/envs/drep/bin/dRep dereplicate /storage1/data12/Projects/Vent_Viruses/dRep/dRep_5kb_debug -g 5kb_VirusGenomes_paths.txt --S_algorithm fastANI -nc .5 -l 5000 -N50W 0 -sizeW 1 --ignoreGenomeQuality --clusterAlg single -p 15 --debug --skip_plots &
```

# Using Seqkit to get genome size of vMAGs

1. I have to run this because the CheckV contig length is going to be off since that was run on vMAGs that were N-linked.
```{bash, eval = FALSE}
conda activate seqkit

mkdir Seqkit

nohup sh -c 'for i in *.fasta ; do seqkit stats $i >> Seqkit/vMAG_Seqkit_stats.tsv ; done' &

less vMAG_Seqkit_stats.tsv  | sed '/^file/d'  | sed 's/.fasta//g' | sed 's/\s\s*/\t/g' > vMAG_stats_parsed.tsv

cut -f1,4-8 vMAG_stats_parsed.tsv | sed '1i Genome\tnum_seqs\tsum_len\tmin_len\tavg_len\tmax_len' > vMAG_stats_parsed_calc.tsv
```
Doing the above and getting the calc file is all you need, I did the part below thinking I need GB...but KB is fine.

```{bash, eval = FALSE}
sed 's/\,//g' vMAG_stats_parsed_calc.tsv | tail +2 | awk '{ printf "%.3f\n", $3/1e+06 }' | sed '1i Genome_Size_MB' > result.txt

paste vMAG_stats_parsed_calc.tsv result.txt > vMAG_GenSizeMB.tsv
```

2. Download the file and combine vMAG genome size in KB with the length of the unbinned virus from column 2 of the CheckV output. Now you have the file of all viruses, binned and unbinned, with genome size in KB to use for plotting and quality checking results.
```{bash, eval = FALSE}
cut -f1,2 quality_summary_vUnbinned_Vents.tsv > vUnbinned_GenSize_KB.tsv

cat Vent_vMAG_GenSize_KB.tsv vUnbinned_GenSize_KB.tsv > Vent_vUnbinned_vMAG_GenSize_KB.tsv
```

# Run GTDBtk v1.5.0 on Vent MAGs

```{bash, eval = FALSE}
conda activate gtdbtk-1.5.0

nohup gtdbtk classify_wf --genome_dir MAGs_Renamed/No_ViralContam/ --out_dir GTDBtk_v1.5.0/ --cpus 15 &
```

# Using Cody's script to parse dRep and skani output

**You need python3.11 for this script**

1. dRep parsing
-a points to the ANI file, which is Nbd.csv for dRep. -c to clusters file, Cdb.csv for dRep
```{bash, eval = FALSE}
conda create -n py311 python=3.11
conda activate py311

mamba install -c conda-forge polars networkx matplotlib numpy python=3.11

/storage1/data14/for_maggie/calc_ani_per_cluster.py -a data_tables/Ndb.csv -c data_tables/Cdb.csv -m fastani-drep
```

2. skani parsing
```{bash, eval = FALSE}
/storage1/data14/for_maggie/calc_ani_per_cluster.py -a /storage1/data12/Projects/Vent_Viruses/skani/PlumeVent/skani_ANI_vUnbinned_vMAGs_PlumeVents.tsv -c /storage1/data12/Projects/Vent_Viruses/mcl_clusters/PlumeVent/vUnbinned_vMAGs_PlumeVents.clusters -m skani-mcl
```

# Using Codys rfasta to split faa unbinned viruses

```{bash, eval = FALSE}
rfasta split -i All_Viruses.faa -d vUnbinned_faa_split -m genome
```

# Clustering viral protein content using mmseqs

1. Run mmseqs. 595,541 proteins between Plume and Vent binned and unbinned viruses.
```{bash, eval = FALSE}
conda install -c bioconda mmseqs2

mmseqs createdb PlumeVent_Viruses.faa PlumeVent_Viruses_DB

nohup mmseqs cluster PlumeVent_Viruses_DB PlumeVent_Viruses_DB_clu /storage1/data12/tmp --cov-mode 0 --min-seq-id 0.75 --threads 20 &

mmseqs createtsv PlumeVent_Viruses_DB PlumeVent_Viruses_DB PlumeVent_Viruses_DB_clu PlumeVent_mmseqs_clusters.tsv --threads 20
```
cov-mode 0 means alignment covers [at least 0.8 of query and of target](https://github.com/soedinglab/mmseqs2/wiki#how-to-set-the-right-alignment-coverage-to-cluster). Using default clustering mode, --cluster-mode 0. This is the [greedy set cover algorithm](https://github.com/soedinglab/mmseqs2/wiki#clustering-modes), which iteratively selects the node with most connections and all its connected nodes to form a cluster and repeats until all nodes are in a cluster.\n

[See here](https://github.com/soedinglab/mmseqs2/wiki#cluster-tsv-format) for explanation of tsv output format.

# Genomad for virus taxonomy

1. Add this to your .bashrc first
```{bash, eval = FALSE}
export LANG="en_US.UTF-8"
```

2. Download genomad with mamba and run it. **Caution when running** genomad uses tensorflow during the classification step and at this step it will significantly overuse the amount of threads you set. It seems like it's using all available CPUs?
```{bash, eval = FALSE}
mamba create -n genomad -c conda-forge -c bioconda genomad

mamba activate genomad

nohup genomad end-to-end --cleanup Virus_Genomes/vUnbinned_vMAGs_1500Ns_PlumeVent.fna genomad_output /storage2/databases/genomad_db/ -t 30 &
```

3. Use Cody's parsing script to get the taxonomy info from genomad into GTDBtk format
```{bash, eval = FALSE}
conda activate

conda install -c conda-forge polars

python /storage1/data14/for_maggie/genomad/fix_genomad_taxonomy.py -i vUnbinned_vMAGs_1500Ns_PlumeVent_taxonomy.tsv -o vUnbinned_vMAGs_1500Ns_PlumeVent_genomad_tax_parsed.txt
```


# Focus on viruses that infect sulfur cycling microbes

## Annotating microbial MAGs

1. Copy data to virserver. Cpying MAGs with no viral contamination. Renamed to remove NoViralContam from names.
```{bash, eval = FALSE}
cp /storage1/data12/Projects/Vent_Viruses/MAGs_Renamed/No_ViralContam/*fna .
```

2. Plume MAGs I already have the faa format MAGs without viral contamination. So just going to translate Vent MAGs on sulfur and then cp faa files to virserver.
```{bash, eval = FALSE}
for sample in *.fna; do prodigal -i $sample -a Prodigal/$sample.faa -o Prodigal/$sample_output.txt; done
```

3 Run the hmm search
```{bash, eval = FALSE}
for file in /scratch/langwig/Databases/Metabolic_genes_hmms/*.hmm; do hmmsearch --cut_tc --cpu 30 --tblout $file.txt $file ../PlumeVent_MAGs_3872.faa; echo "next hmm"; done
```

4. Get best hits
```{bash, eval = FALSE}
for i in *.txt; do python3 /storage2/scratch/langwig/scripts/hmm_parser.py -i $i -o $i.parsed.txt; done
```
**Note that some are 0 because did not have trusted cutoff**. \n
**Also this did not actually grab best hits as expected but organized nicely**

### Sulfur hmm search parsing

**File that is named subset_sulfurHMM_MAG_names_final_uniq.txt contains the names of microbial MAGs that encode aprA, dsrABD, fccB, soxBCY, or phsA**

Wild sed commands to get rid of annoying names...
```{bash, eval = FALSE}
sed 's/_355-202/\t/2' subset_sulfurHMM_MAGs_final_uniq.txt | cut -f1 | sed 's/_354-166/\t/2' | sed 's/_4571-419/\t/2' | sed 's/_4562-384/\t/2' | sed 's/_4562-384/\t/2' | sed 's/_4561-380/\t/2' | sed 's/_4559-240/\t/2' | sed 's/_4281-140/\t/2' | sed 's/_4562-384/\t/2' | sed 's/_PIR-30/\t/2' | sed 's/_V2/\t/2' | sed 's/_T2/\t/2' | sed 's/_T11/\t/2' | sed 's/_T10/\t/2' | sed 's/_M2/\t/2' | sed 's/_M17/\t/2' | sed 's/_M1/\t/2' | cut -f1 | sed 's/_A3/\t/2' | sed 's/_A1/\t/2' | sed 's/_134-614/\t/2' | sed 's/_132-544/\t/2' | sed 's/_131-447/\t/2' | sed 's/_128-326/\t/2' | sed 's/_S147/\t/2' | sed 's/_S146/\t/2' | sed 's/_S145/\t/2' | sed 's/_S144/\t/2' | sed 's/_S14/\t/2'| cut -f1 | sed 's/_S13/\t/2' | cut -f1 | sed 's/_S0/\t/2' | cut -f1 | sort | uniq > subset_sulfurHMM_MAGs_final_uniq_namesFixed.txt
```

## Annotations of blast-based iphop matches

What are the genes that link viruses and hosts based on blast output of iphop?

1. Get viruses that infect sulfur cyclers from BLAST file
```{bash, eval = FALSE}
for i in `cat sulfur_Virus_list.txt`; do grep -w $i ../../iphop/iphop_vUnbinned_vMAG_1500Ns_MAGdb/blastgenomes_seqids.txt >> blastgenomes_seqids_sulfur.txt; done
```

2. Then grab the matches to sulfur cycling MAGs, leave out ref genomes
```{bash, eval = FALSE}
for i in `cat sulfur_MAG_list_50comp.txt`; do grep -w $i blastgenomes_seqids_sulfur.txt >> blastgenomes_seqids_sulfur_VirusMAG.txt; done
```

3. Get coordinates for MAGs
```{bash, eval = FALSE}
cut -f3,6,7 blastgenomes_seqids_sulfur_VirusMAG.txt > MAG_coordinates.txt

bedtools getfasta -fi ../../../MAGs_microbial/PlumeVent_MAGs_3872.fna -bed MAG_coordinates.txt -fo PlumeVent_MAGs_sulfurVirus_blastGenes.fna -s
```

### Trying blastp because parsing is hard

```{bash, eval = FALSE}
diamond makedb --in sulfur_MAGs.faa -d sulfur_MAGs.db

diamond blastp --db GenomesToBlast/sulfur_MAGs.db.dmnd --query GenomesToBlast/sulfur_vUnbinned_vMAGs.faa --out VentPlume_Virus_toMAGs_diamond.txt --id 80 --evalue 1e-3 --threads 25 --outfmt 6 qtitle stitle pident length qstart qend sstart send evalue bitscore --max-target-seqs 1 &
```

## Comparison of sulfur viruses to GOV

I want to see if the viruses that infect sulfur cycling microbes are similar to viruses from the GOV.

1. Download GOV from this [link](https://de.cyverse.org/data/ds/iplant/home/shared/iVirus/GOV2.0) in CyVerse

2. Use skani to compare ANI
```{bash, eval = FALSE}
cat GOV2_viral_populations_larger_than_5KB_or_circular.fasta ../skani/sulfur_viruses/sulfur_vUnbinned.fna > sulfur_vUnbinned_GOV5kb_circ.fasta

nohup /storage1/data14/software/skani-vMAG/python/skani-vMAG.py -c sulfur_vUnbinned_GOV5kb_circ.fasta -d ../skani/sulfur_viruses/VirusGenomes/vMAGs/VirusGenomes/vMAGs/ -x .fasta --outdir . -o sulfurVirus50comp_GOV_skani_ani.tsv -f 50.0 -t 30 &
```








